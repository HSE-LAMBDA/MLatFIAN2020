{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLatFIAN-2020-seminar08-MISC.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPp5qERVzXV7ELXYgvaMckP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HSE-LAMBDA/MLatFIAN2020/blob/master/seminar08/MLatFIAN_2020_seminar08_MISC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRVZP73cZZQy"
      },
      "source": [
        "!wget https://github.com/HSE-LAMBDA/MLatFIAN2020/raw/master/seminar01/train.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqIgHWdLZvGS"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('train.csv', index_col='PassengerId')\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVr1QWpszpdB"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_train, data_test = train_test_split(data, test_size=100, random_state=123)\n",
        "def get_Xy(Xy):\n",
        "  return Xy.drop('Survived', axis=1), Xy['Survived']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6bJVp95x-nJ"
      },
      "source": [
        "# Combining preprocessors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PVjNN4WyEjP"
      },
      "source": [
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
        "from sklearn.impute import SimpleImputer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iKXgoIwyhLp"
      },
      "source": [
        "categorical_pipeline = make_pipeline(\n",
        "    SimpleImputer(strategy='constant', fill_value='unknown'),\n",
        "    OneHotEncoder()\n",
        ")\n",
        "numecir_pipeline = make_pipeline(\n",
        "    SimpleImputer(strategy='median'),\n",
        "    RobustScaler()\n",
        ")\n",
        "\n",
        "categorical_features = ['Pclass', 'Sex', 'Embarked']\n",
        "numeric_features = ['Age', 'SibSp', 'Fare']\n",
        "\n",
        "model = make_pipeline(\n",
        "    make_column_transformer(\n",
        "        (categorical_pipeline, categorical_features),\n",
        "        (numecir_pipeline, numeric_features),\n",
        "        remainder='drop'\n",
        "    ),\n",
        "    XGBClassifier()\n",
        ")\n",
        "\n",
        "model.fit(*get_Xy(data_train))\n",
        "model.score(*get_Xy(data_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZ-TYEUI9QSs"
      },
      "source": [
        "ohe = model['columntransformer'].named_transformers_['pipeline-1']['onehotencoder']\n",
        "final_features = [\n",
        "    f'{feature}_{val}'\n",
        "    for feature, category_set in zip(categorical_features, ohe.categories_)\n",
        "    for val in category_set\n",
        "]\n",
        "final_features += numeric_features\n",
        "final_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Xm1sT4Z3izB"
      },
      "source": [
        "print(f'{\"importance\":12s}      {\"feature\":15s}')\n",
        "for i in np.argsort(model[-1].feature_importances_)[::-1]:\n",
        "  print(f'{model[-1].feature_importances_[i]:12.3f}      {final_features[i]:15s}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mM2SEQx74o_x"
      },
      "source": [
        "# Permutation importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68bFYJLzAowi"
      },
      "source": [
        "!pip install eli5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQipo-5pAonR"
      },
      "source": [
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvFSKPEBAob-"
      },
      "source": [
        "perm = PermutationImportance(model[-1], random_state=1)\n",
        "X_test, y_test = get_Xy(data_test)\n",
        "perm.fit(\n",
        "    model[:-1].transform(X_test),\n",
        "    y_test\n",
        ")\n",
        "\n",
        "eli5.show_weights(perm, feature_names=final_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBefXe5uyg1c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu-ik8NbUU9D"
      },
      "source": [
        "# Working with text features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIYeAxclZ2yz"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k41gcP93xDfk"
      },
      "source": [
        "vec = CountVectorizer(\n",
        "#    ngram_range=(1, 2)\n",
        ")\n",
        "\n",
        "text = [\n",
        "  \"Hello! I'm Jack. What's your name?\",\n",
        "  \"Hi! My name is Jill. Pleased to meet you!\",\n",
        "  \"Pleased to meet you too!\"\n",
        "]\n",
        "\n",
        "vec.fit(text)\n",
        "vec.vocabulary_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4z0dUep0zB51"
      },
      "source": [
        "columns = np.empty(shape=len(vec.vocabulary_), dtype='object')\n",
        "for k, v in vec.vocabulary_.items():\n",
        "  columns[v] = k\n",
        "\n",
        "pd.DataFrame(vec.transform(text).todense(), columns=columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiC5OHVYvvJr"
      },
      "source": [
        "vec = CountVectorizer(\n",
        "  ngram_range=(3, 4),\n",
        "  analyzer='char_wb',\n",
        "  max_features=100\n",
        ")\n",
        "\n",
        "vec.fit(get_Xy(data_train)[0]['Name'])\n",
        "\n",
        "columns = np.empty(shape=len(vec.vocabulary_), dtype='object')\n",
        "for k, v in vec.vocabulary_.items():\n",
        "  columns[v] = k\n",
        "\n",
        "pd.DataFrame(vec.transform(get_Xy(data_train)[0]['Name']).todense(), columns=columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScMScaXtev5K"
      },
      "source": [
        "model = make_pipeline(\n",
        "    make_column_transformer(\n",
        "      (CountVectorizer(\n",
        "         ngram_range=(3, 4),\n",
        "         analyzer='char_wb',\n",
        "         max_features=100\n",
        "       ), 'Name'),\n",
        "       remainder='drop'\n",
        "    ),\n",
        "    XGBClassifier()\n",
        ")\n",
        "\n",
        "model.fit(*get_Xy(data_train))\n",
        "model.score(*get_Xy(data_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zII_NVhf5m7"
      },
      "source": [
        "eli5.show_weights(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9lfFnQpW3yl"
      },
      "source": [
        "name = X_test['Name'].iloc[0]\n",
        "print(name)\n",
        "\n",
        "eli5.show_prediction(\n",
        "    model[-1], name,\n",
        "    show_feature_values=True, vec=model[0].named_transformers_['countvectorizer'],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ax6aaEc4vMsC"
      },
      "source": [
        "name = X_test['Name'].iloc[5]\n",
        "print(name)\n",
        "\n",
        "eli5.show_prediction(\n",
        "    model[-1], name,\n",
        "    show_feature_values=True, vec=model[0].named_transformers_['countvectorizer'],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxadPW2xBL4t"
      },
      "source": [
        "# Numeric + Categorical + Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U91SiI5JBYnd"
      },
      "source": [
        "all_columns = list(get_Xy(data_train)[0].columns)\n",
        "\n",
        "categorical_pipeline = make_pipeline(\n",
        "    SimpleImputer(strategy='constant', fill_value='unknown'),\n",
        "    OneHotEncoder()\n",
        ")\n",
        "numecir_pipeline = make_pipeline(\n",
        "    SimpleImputer(strategy='median'),\n",
        "    RobustScaler()\n",
        ")\n",
        "text_pipeline = CountVectorizer(\n",
        "  ngram_range=(3, 4),\n",
        "  analyzer='char_wb',\n",
        "  max_features=100\n",
        ")\n",
        "\n",
        "categorical_features = ['Pclass', 'Sex', 'Embarked']\n",
        "numeric_features = ['Age', 'SibSp', 'Fare']\n",
        "text_features = 'Name'\n",
        "\n",
        "model = make_pipeline(\n",
        "    make_column_transformer(\n",
        "        (categorical_pipeline, [all_columns.index(f) for f in categorical_features]),\n",
        "        (numecir_pipeline, [all_columns.index(f) for f in numeric_features]),\n",
        "        (text_pipeline, all_columns.index(text_features)),\n",
        "        remainder='drop'\n",
        "    ),\n",
        "    XGBClassifier()\n",
        ")\n",
        "\n",
        "model.fit(*get_Xy(data_train))\n",
        "model.score(*get_Xy(data_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbjX99pBCqlq"
      },
      "source": [
        "model['columntransformer'].named_transformers_['pipeline-1'].get_feature_names = (\n",
        "    lambda: [\n",
        "      f'{feature}_{val}'\n",
        "      for feature, category_set in zip(\n",
        "          categorical_features,\n",
        "          model['columntransformer'].named_transformers_['pipeline-1']['onehotencoder'].categories_\n",
        "      ) for val in category_set\n",
        "    ]\n",
        ")\n",
        "\n",
        "model['columntransformer'].named_transformers_['pipeline-2'].get_feature_names = (\n",
        "    lambda: numeric_features\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6NaIodGBpWg"
      },
      "source": [
        "obj = X_test.iloc[0]\n",
        "print(obj['Name'])\n",
        "\n",
        "eli5.show_prediction(\n",
        "    model[-1], obj.values,\n",
        "    show_feature_values=True, vec=model['columntransformer'],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XLXInsjHth_"
      },
      "source": [
        "# Calibration curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1eVrrVpHuJn"
      },
      "source": [
        "from sklearn.calibration import calibration_curve\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgIm34v0II6N"
      },
      "source": [
        "plt.figure(figsize=(5, 5), dpi=100)\n",
        "\n",
        "plt.plot(*calibration_curve(y_test, model.predict_proba(X_test)[:,1], n_bins=5, strategy='quantile'))\n",
        "plt.plot([0, 1], [0, 1], '--', color='black')\n",
        "plt.xlabel(\"fraction of positives\")\n",
        "plt.ylabel(\"predicted probability\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MReHa0yYKBq_"
      },
      "source": [
        "from sklearn.calibration import CalibratedClassifierCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9V282NthKEOa"
      },
      "source": [
        "calibrated_model = make_pipeline(\n",
        "    make_column_transformer(\n",
        "        (categorical_pipeline, [all_columns.index(f) for f in categorical_features]),\n",
        "        (numecir_pipeline, [all_columns.index(f) for f in numeric_features]),\n",
        "        (text_pipeline, all_columns.index(text_features)),\n",
        "        remainder='drop'\n",
        "    ),\n",
        "    CalibratedClassifierCV(XGBClassifier(), cv=3, method='isotonic')\n",
        ")\n",
        "\n",
        "calibrated_model.fit(*get_Xy(data_train));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hmybj_liKltV"
      },
      "source": [
        "plt.figure(figsize=(5, 5), dpi=100)\n",
        "\n",
        "plt.plot(*calibration_curve(y_test, model.predict_proba(X_test)[:,1], n_bins=5, strategy='quantile'),\n",
        "         label='before calibration')\n",
        "plt.plot(*calibration_curve(y_test, calibrated_model.predict_proba(X_test)[:,1], n_bins=5, strategy='quantile'),\n",
        "         label='after calibration')\n",
        "plt.plot([0, 1], [0, 1], '--', color='black')\n",
        "plt.xlabel(\"fraction of positives\")\n",
        "plt.ylabel(\"predicted probability\");\n",
        "plt.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGdNRnuEM56m"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}