{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLatFIAN2020_seminar01_part2_SimpleMLFit.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HSE-LAMBDA/MLatFIAN2020/blob/master/seminar01/MLatFIAN2020_seminar01_part2_SimpleMLFit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XIaSpYS6WFC",
        "colab_type": "text"
      },
      "source": [
        "# Let's do a Maximum Likelihood fit!\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "We'll need an extra package called `probfit` which is not available by default. It takes some time to install, so please run the installation command now:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahiuQPaKhW5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install probfit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssW-O_gm7oQd",
        "colab_type": "text"
      },
      "source": [
        "## What we'll need\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "*   ### Get and select the data\n",
        "*   ### Define the Likelihood function\n",
        "*   ### Maximize it (minimize negative Likelihood)\n",
        "*   ### Plot the result\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTG8qhewiMp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We'll store and handle our data with numpy.\n",
        "#\n",
        "# Also, we'll start by working with 'toy' data, i.e. we are\n",
        "# going to randomly generate our data - we'll use numpy for\n",
        "# that as well.\n",
        "import numpy as np\n",
        "\n",
        "# The plotting will be done in matplotlib:\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ut8EMzUeXXxL",
        "colab_type": "text"
      },
      "source": [
        "## Toy data\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "In reality we don't usually detect just the decays we are looking for. Usually, there are also other processes that have the same signature as the process of interest, and there is no deterministic way to tell them apart.\n",
        "\n",
        "\n",
        "Let's emulate this in our toy data!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzYUeO6hVvxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Say, there's some particle with a mass of 125.18 GeV,\n",
        "# which we can only measure with an uncertainty of 15 GeV:\n",
        "signal = np.random.normal(loc=125.18, scale=15., size=10000)\n",
        "\n",
        "# Then, imagine there are some continuous backgound processes\n",
        "# with the same signature, which contribute to our particle\n",
        "# mass measurement and are distributed as decaying exponent:\n",
        "background = np.random.exponential(scale=80., size=90000)\n",
        "\n",
        "# In real life there's no deterministic way to tell them apart,\n",
        "# as they are 'shuffled' together:\n",
        "data = np.concatenate([signal, background])\n",
        "np.random.shuffle(data)\n",
        "\n",
        "print(\"data.shape = {}\".format(data.shape))\n",
        "print(\"data = {}\".format(data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrFC5aWRbmHK",
        "colab_type": "text"
      },
      "source": [
        "Now, `data` is a 1-dimentional array each element of which represents distinct mass measurements. Let's see what it looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akhdkRETibVC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(data, bins=100, alpha=0.8);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqNpq8_ReSOz",
        "colab_type": "text"
      },
      "source": [
        "OK, that's nice, but we probably don't need such a wide range. Let's only select the data from 10 to 200 GeV:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4gXWe-eeR-v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We'll define a tuple with our selection range, as\n",
        "# this will come in handy later\n",
        "mass_bound = (10., 200.)\n",
        "\n",
        "data = data[(data > mass_bound[0]) & (data < mass_bound[1])]\n",
        "plt.hist(data, bins=100, alpha=0.8);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlIsKiDXri6a",
        "colab_type": "text"
      },
      "source": [
        "## Defining the model PDF and Likelihood functions\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "OK, remember we installed something at the beginning of the section? It was `probfit` â€” a package that makes PDF and Likelihood definition really easy (see [this page](https://probfit.readthedocs.io/en/latest/index.html) for more details; they also have a good [tutorial here](http://nbviewer.ipython.org/urls/raw.github.com/scikit-hep/probfit/master/tutorial/tutorial.ipynb)). Let's import the package:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s29CZe5zguZk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import probfit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6Ga5lxttCYz",
        "colab_type": "text"
      },
      "source": [
        "PDFs can just be python functions with the following signature:\n",
        "\n",
        "`function_name(x, param1, param2, ...)`\n",
        "\n",
        "However, one has to make sure they integrate up to 1:\n",
        "$$\\int_{\\text{domain}}\\text{PDF}(x)dx = 1$$\n",
        "\n",
        "Since we've selected our data to be in the interval $(10, 200)~$GeV, we have to normalize our PDFs such that\n",
        "$$\\int_{10~\\text{GeV}}^{200~\\text{GeV}}\\text{PDF}(x)dx = 1$$\n",
        "\n",
        "As our data is a mixture of a peaking signal and a continuous background, we'll define the PDF in the following form:\n",
        "$$\\text{PDF}(x|m,\\sigma,k, f_{\\text{sig}}) = \n",
        "f_{\\text{sig}}\\cdot \\mathscr{N}(x|m, \\sigma) +\n",
        "(1 - f_{\\text{sig}})\\cdot k e^{-kx},$$\n",
        "where:\n",
        "\n",
        "\n",
        "*   $x$ is the value of mass from an individual measurement\n",
        "*   $m$ is the actual mass of the decaying particle\n",
        "*   $sigma$ is detector resolution\n",
        "*   $\\mathscr{N}(x|m, \\sigma)$ is normal (Gaussian) distribution\n",
        "*   $k$ is the empirical background slope\n",
        "*   $f_{\\text{sig}}$ is the fraction of signal in the mixture\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgojAu5U0gk3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For the Gaussian we'll use the function already defined in\n",
        "# probfit and just wrap it around our custom python function\n",
        "# to rename the parameters\n",
        "def SignalPDF(x, mass, sigma):\n",
        "  return probfit.gaussian(x, mass, sigma)\n",
        "\n",
        "# As for the exponential function, we'll define it ourselves\n",
        "def BgPDF(x, exp_slope):\n",
        "  return exp_slope * np.exp(-exp_slope * x)\n",
        "\n",
        "# So far our functions are normalized differently:\n",
        "#     SignalPDF is normalized for x in [-infinity, +infinity]\n",
        "#     BgPDF is normalized for x in [0 GeV, +infinity]\n",
        "# We need them both to be normalized for x in [10, 200] GeV.\n",
        "\n",
        "# Luckily, probfit has a convinient 'Normalize' class for that:\n",
        "SignalPDF_normed = probfit.Normalized(SignalPDF, mass_bound)\n",
        "BgPDF_normed     = probfit.Normalized(BgPDF    , mass_bound)\n",
        "\n",
        "# There's also a ready to use class to combine several PDFs in a sum:\n",
        "ModelPDF = probfit.AddPdfNorm(SignalPDF_normed,\n",
        "                              BgPDF_normed,\n",
        "                              facname=['signal_fraction'])\n",
        "# OK, our PDF is ready!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJquCQIM0kzE",
        "colab_type": "text"
      },
      "source": [
        "Now we have to define the Likelihood function for a set of measurements $\\{x_i\\}$:\n",
        "$$\\mathscr{L}(m,\\sigma,k, f_{\\text{sig}}) = \\prod_i{\\text{PDF}(x_i|m,\\sigma,k, f_{\\text{sig}})}$$\n",
        "\n",
        "There's a ready to use class for that as well:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCK5H4s00lQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unbinned_likelihood = probfit.UnbinnedLH(ModelPDF, data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lO-2syhX2NK9",
        "colab_type": "text"
      },
      "source": [
        "## Maximizing the Likelihood!\n",
        "\n",
        "Actually, will **minimize** the  $-log(\\mathscr{L})$, which has the same effect. In HEP it's a common practice to use [the MINUIT program](https://en.wikipedia.org/wiki/MINUIT) for minimization. It was originally written in 1970s in CERN and its Migrad algorithm has proven to be super robust and stable.\n",
        "\n",
        "Although MINUIT is a C++ program (originally â€“ FORTRAN), there is a python wrapper called `iminuit`. Let's import it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d54Tdvnnhb7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import iminuit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYnVFWnh8eaF",
        "colab_type": "text"
      },
      "source": [
        "In order to run the minimization, one has to:\n",
        "\n",
        "\n",
        "*   create an instance of `iminuit.Minuit` class\n",
        "*   give it an instance to the function to be minimized\n",
        "*   set up initial parameter values\n",
        "*   set up parameter limits (optional, recommended)\n",
        "*   set up initial steps for parameter variations (optional)\n",
        "\n",
        "Firstly, let's see which parameters does our PDF have:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moSpx3y6rAhT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(iminuit.describe(unbinned_likelihood))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7fM8SO69qJM",
        "colab_type": "text"
      },
      "source": [
        "So, for the set of measurements $\\{x_i\\}$ our Likelihood will be a function of the following parameters:\n",
        "```\n",
        "mass\n",
        "sigma\n",
        "exp_slope\n",
        "signal_fraction```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kINi5K4VrDps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We'll define dictionaries of our parameter values.\n",
        "\n",
        "# This will be our initial guess:\n",
        "initial_par_values = dict(\n",
        "  mass           =120.  ,\n",
        "  sigma          = 25.  ,\n",
        "  exp_slope      =  0.01,\n",
        "  signal_fraction=  0.4 ,\n",
        ")\n",
        "\n",
        "# We'll define the limits:\n",
        "limits = dict(\n",
        "  limit_mass           =(50. , 200.),\n",
        "  limit_sigma          =( 3. , 150.),\n",
        "  limit_exp_slope      =(1e-4,   1.),\n",
        "  limit_signal_fraction=( 0. ,   1.),\n",
        ")\n",
        "\n",
        "# And initial variation steps:\n",
        "errors = dict(\n",
        "  error_mass           =10.  ,\n",
        "  error_sigma          =10.  ,\n",
        "  error_exp_slope      =0.005,\n",
        "  error_signal_fraction=0.2  ,\n",
        ")\n",
        "\n",
        "# Finally, let's create the minimizer:\n",
        "minuit = iminuit.Minuit(\n",
        "            unbinned_likelihood, **initial_par_values, **limits, **errors)\n",
        "\n",
        "\n",
        "# N.B. If you're not familiar with the `func(**arg)` notation,\n",
        "# the following two code snippets do the same thing:\n",
        "#\n",
        "#     arg = dict(x=1, y=2)\n",
        "#     func(**arg)\n",
        "#\n",
        "# and\n",
        "#\n",
        "#     func(x=1, y=1)\n",
        "#\n",
        "# except that in the first case you also get a dictionary `arg` with the\n",
        "# following content:\n",
        "#\n",
        "#     {'x' : 1, 'y' : 2}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHXhwvHS_5kZ",
        "colab_type": "text"
      },
      "source": [
        "OK, let's see how good our guess was:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwS7VDDNrEZy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unbinned_likelihood.draw(minuit=minuit);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyvvM7LmABqi",
        "colab_type": "text"
      },
      "source": [
        "Not perfect. Now, let's run the minimization algorithm:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uB5Fyr9Cqro2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "minuit.migrad()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPEnmrYsA-pk",
        "colab_type": "text"
      },
      "source": [
        "Nice! It also prints out the results. You want to make sure that the fit was successful (Valid == True), that none of your parameters has hit it's range limits, and also that the error matrix is positively defined (PosDef = True).\n",
        "\n",
        "Let's run the accurate hessian estimating algorithm:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXbTfHcdZBjR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "minuit.hesse()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAQnSUhmjlal",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We've already used this function to plot our PDF against the data before.\n",
        "# Now we've added a few parameters:\n",
        "#   `parts=True` enables different components drawing, i.e. we'll see the\n",
        "#                exponent and Gaussian independently\n",
        "#   `parmloc` specifies where the fitted parameters printout will be located.\n",
        "unbinned_likelihood.draw(minuit=minuit, parts=True, parmloc=(0.45, 0.95));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPL-T8sVCyyP",
        "colab_type": "text"
      },
      "source": [
        "# Bonus part: speeding things up with Cython\n",
        "\n",
        "[Cython](https://cython.org/) is an extension that allows you to convert python-like code to C, compile it and import the resulting objects back into your python session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIfO270Nj9Xj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install Cython\n",
        "%load_ext Cython"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDaFzccnFC8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%cython --annotate\n",
        "\n",
        "cimport cython\n",
        "from libc.math cimport exp, M_PI, sqrt\n",
        "\n",
        "@cython.binding(True)\n",
        "def gauss_pdf_cython(double x, double mass, double sigma):\n",
        "  return 1 / sqrt(2 * M_PI) / sigma * exp(-(x - mass)**2 / 2. / sigma**2)\n",
        "\n",
        "@cython.binding(True)\n",
        "def exp_pdf_cython(double x, double exp_slope):\n",
        "  return exp(-exp_slope * x) * exp_slope\n",
        "\n",
        "# See this for more info on binding:\n",
        "# https://cython.readthedocs.io/en/latest/src/userguide/source_files_and_compilation.html#compiler-directives"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utvt1Aomntvv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gauss_pdf_cython_normed = probfit.Normalized(gauss_pdf_cython, mass_bound)\n",
        "exp_pdf_cython_normed   = probfit.Normalized(exp_pdf_cython  , mass_bound)\n",
        "\n",
        "\n",
        "ModelPDF_cython = probfit.AddPdfNorm(gauss_pdf_cython_normed,\n",
        "                                     exp_pdf_cython_normed,\n",
        "                                     facname=['signal_fraction'])\n",
        "print(iminuit.describe(ModelPDF_cython))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knj0fVSRnthG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unbinned_likelihood_cython = probfit.UnbinnedLH(ModelPDF_cython, data)\n",
        "\n",
        "minuit_cython = iminuit.Minuit(\n",
        "                    unbinned_likelihood_cython,\n",
        "                    **initial_par_values, **limits, **errors)\n",
        "\n",
        "unbinned_likelihood_cython.draw(minuit=minuit_cython, parts=True, parmloc=(0.45, 0.95));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlO8mqHhntWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%timeit -n1 -r1 minuit_cython.migrad();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UgOmSGEj9Ej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unbinned_likelihood_cython.draw(minuit=minuit_cython, parts=True, parmloc=(0.45, 0.95));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHnSrcDqaUMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "el3PY7bEeY3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU96WDCveY6q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFBp6Tm_eY9v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmHGohKqmhSk",
        "colab_type": "text"
      },
      "source": [
        "# Bonus part 2: pure `iminuit` without `probfit`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52A6zdwxmr7i",
        "colab_type": "text"
      },
      "source": [
        "Probfit is great but it's limited to a single observalbe. Here we'll demonstrate a maximum likelihood fit with pure `iminuit` when there's two observables.\n",
        "\n",
        "Our true data will be distributed as\n",
        "$$y = 2\\cdot x^2 - x + \\text{noise}.$$\n",
        "\n",
        "The two observables will be:\n",
        "$$x_1 \\equiv x$$\n",
        "$$x_2 \\equiv x^2$$\n",
        "\n",
        "and our model is:\n",
        "$$p\\left(y|x, w_1, w_2, \\sigma\\right)\n",
        "=\\mathscr{N}(y|\\mu(x), \\sigma^2)$$\n",
        "$$\\mu(x)=w_1\\cdot x + w_2\\cdot x^2$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OZcPtrKeaRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N = 200\n",
        "\n",
        "x = np.random.uniform(size=N)\n",
        "X = np.stack([\n",
        "    x, x**2\n",
        "], axis=1)\n",
        "\n",
        "y = np.dot([-1., 2.], X.T)\n",
        "y += np.random.normal(size=y.shape) * 0.1\n",
        "\n",
        "print(X.shape, y.shape)\n",
        "\n",
        "plt.scatter(x, y);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFOl_r_FfLvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def PDF(y, X, w1, w2, sigma):\n",
        "  return (1. / np.sqrt(2 * np.pi) / sigma) * np.exp(\n",
        "      -(y - np.dot([w1, w2], X.T))**2 / (2 * sigma**2)\n",
        "  )\n",
        "\n",
        "def NLL(w1, w2, sigma):\n",
        "  return -np.log(PDF(y, X, w1, w2, sigma)).sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivrbCgmsir7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iminuit.describe(NLL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZMgmZcei2ls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "minuit = iminuit.Minuit(\n",
        "    NLL,\n",
        "    w1=0., w2=0., sigma=1.0,\n",
        "    limit_sigma=(0.001, 10.),\n",
        "    limit_w1=(-1000., 1000.),\n",
        "    limit_w2=(-1000., 1000.),\n",
        "    error_w1=1., error_w2=1., error_sigma=0.1,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsAEnW7yjA57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "minuit.migrad()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRA1tg-iljsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "minuit.hesse()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsUiHQOmlpKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "minuit.draw_contour(\"w1\", \"w2\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmNtBrwQmNXx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}